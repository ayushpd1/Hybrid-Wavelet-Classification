{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2c2935-be98-406b-b40b-09a94715b5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, zipfile, random\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib  \n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bab7d3-6661-4316-a02e-bfcc36dc85bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: (145, 145, 200) gt: (145, 145)\n"
     ]
    }
   ],
   "source": [
    "data_mat = sio.loadmat(\"Indian_pines_corrected.mat\")\n",
    "gt_mat   = sio.loadmat(\"Indian_pines_gt.mat\")\n",
    "\n",
    "data = data_mat['indian_pines_corrected']   \n",
    "gt   = gt_mat['indian_pines_gt']            \n",
    "\n",
    "print(\"data:\", data.shape, \"gt:\", gt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56506838-a0d5-4611-a64a-9209eefa3096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After PCA: (145, 145, 30)\n"
     ]
    }
   ],
   "source": [
    "n_components = 30\n",
    "\n",
    "H,W,B = data.shape\n",
    "data_reshaped = data.reshape(-1, B).astype(np.float32)\n",
    "band_mean = data_reshaped.mean(axis=0)\n",
    "band_std  = data_reshaped.std(axis=0) + 1e-12\n",
    "data_norm = (data_reshaped - band_mean) / band_std\n",
    "\n",
    "pca = PCA(n_components=n_components, whiten=True, random_state=seed)\n",
    "data_pca_flat = pca.fit_transform(data_norm)    \n",
    "data_pca = data_pca_flat.reshape(H, W, n_components)\n",
    "\n",
    "joblib.dump({'pca': pca, 'mean': band_mean, 'std': band_std}, 'pca_and_norm.joblib')\n",
    "\n",
    "print(\"After PCA:\", data_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03db1900-8c7c-44b1-9ee2-394f7bb5c03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted patches: (10249, 25, 25, 30) labels: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16]\n"
     ]
    }
   ],
   "source": [
    "patch_size = 25\n",
    "pad = patch_size // 2\n",
    "\n",
    "data_pad = np.pad(data_pca, ((pad,pad),(pad,pad),(0,0)), mode='constant')\n",
    "gt_pad   = np.pad(gt, ((pad,pad),(pad,pad)), mode='constant')\n",
    "\n",
    "patches = []\n",
    "labels  = []\n",
    "H0, W0 = gt.shape\n",
    "for i in range(pad, pad + H0):\n",
    "    for j in range(pad, pad + W0):\n",
    "        lab = gt_pad[i, j]\n",
    "        if lab == 0:\n",
    "            continue  \n",
    "        patch = data_pad[i-pad:i+pad+1, j-pad:j+pad+1, :]  \n",
    "        patches.append(patch.astype(np.float32))\n",
    "        labels.append(int(lab))  \n",
    "\n",
    "patches = np.array(patches)  \n",
    "labels  = np.array(labels)    \n",
    "print(\"Extracted patches:\", patches.shape, \"labels:\", np.unique(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c350b2c2-8bc8-48ac-a62e-8b3460001531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1018, 25, 25, 30) (1018,)\n",
      "Test: (9231, 25, 25, 30) (9231,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "unique_labels = np.unique(labels)\n",
    "train_idx_list = []\n",
    "test_idx_list  = []\n",
    "\n",
    "for c in unique_labels:\n",
    "    idx_c = np.where(labels == c)[0]\n",
    "\n",
    "    idx_c_sorted = np.array(idx_c)\n",
    "\n",
    "    n_train = max(1, int(0.10 * len(idx_c_sorted))) \n",
    "    tr_idx, te_idx = train_test_split(idx_c_sorted, train_size=n_train, random_state=seed, shuffle=True)\n",
    "    train_idx_list.append(tr_idx)\n",
    "    test_idx_list.append(te_idx)\n",
    "\n",
    "train_idx = np.concatenate(train_idx_list)\n",
    "test_idx  = np.concatenate(test_idx_list)\n",
    "\n",
    "X_train = patches[train_idx]\n",
    "y_train = labels[train_idx] - 1   \n",
    "X_test  = patches[test_idx]\n",
    "y_test  = labels[test_idx] - 1\n",
    "\n",
    "\n",
    "perm = np.random.RandomState(seed).permutation(len(X_train))\n",
    "X_train = X_train[perm]; y_train = y_train[perm]\n",
    "\n",
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Test:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a0012b-6020-4f66-ab06-e12d5071a4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HSIDataset(Dataset):\n",
    "    def __init__(self, X, y, augment=False):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx].transpose(2,0,1)  \n",
    "        if self.augment:\n",
    "            if random.random() > 0.5:\n",
    "                x = np.flip(x, axis=1)\n",
    "            if random.random() > 0.5:\n",
    "                x = np.flip(x, axis=2)\n",
    "        x = torch.from_numpy(x).unsqueeze(0).float()  \n",
    "        y = torch.tensor(self.y[idx]).long()\n",
    "        return x, y\n",
    "\n",
    "train_dataset = HSIDataset(X_train, y_train, augment=True)\n",
    "test_dataset  = HSIDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4ca08c-ccea-42a5-8653-f062e4b4811c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: preprocessedd/ (stored 0%)\n",
      "  adding: preprocessedd/y_train.npy (deflated 88%)\n",
      "  adding: preprocessedd/y_test.npy (deflated 100%)\n",
      "  adding: preprocessedd/X_test.npy (deflated 12%)\n",
      "  adding: preprocessedd/X_train.npy (deflated 12%)\n",
      "Saved and zipped preprocessedd/hsi_data_pca.zip\n"
     ]
    }
   ],
   "source": [
    "\n",
    "os.makedirs(\"preprocessedd\", exist_ok=True)\n",
    "np.save(\"preprocessedd/X_train.npy\", X_train)\n",
    "np.save(\"preprocessedd/y_train.npy\", y_train)\n",
    "np.save(\"preprocessedd/X_test.npy\", X_test)\n",
    "np.save(\"preprocessedd/y_test.npy\", y_test)\n",
    "\n",
    "!zip -r hsi_data_pca.zip preprocessedd\n",
    "print(\"Saved and zipped preprocessedd/hsi_data_pca.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0e312d6-9de9-4650-bdf8-4cae5ac87e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: preprocessedd/ (stored 0%)\n",
      "  adding: preprocessedd/y_train.npy (deflated 88%)\n",
      "  adding: preprocessedd/y_test.npy (deflated 100%)\n",
      "  adding: preprocessedd/X_test.npy (deflated 12%)\n",
      "  adding: preprocessedd/X_train.npy (deflated 12%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r hsi_data.zip preprocessedd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
